version: "3.7"

services:
  proxy:
    build: proxy
    restart: always
    ports:
      - "8010:80"
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./proxy:/etc/nginx/conf.d

  address_parser:
    build: ../address-parser-service/app
    restart: always
    expose:
      - 660
    environment:
      - END_POINT=/parse
      - FEEDBACK_ENDPOINT=/feedback
      - FEEDBACK_PATH=/app/feedback_data
      - MODEL_PATH=/app/weights/best
    volumes:
      - ../address-parser-service/app:/app
    deploy:
      replicas: 2
    command: uvicorn entry_point:app --port 660 --host 0.0.0.0

  geocoding:
    build: ../geocoding-api/app
    restart: always
    expose:
      - 660
    environment:
      - END_POINT=/geocoding/geocode
      - GET_GEO_DATA_END_POINT=/geocoding/get_geo_data
      - ADDRESS_PARSER_URL=http://proxy:80/address_parser/parse
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    volumes:
      - ../geocoding-api/app:/app
    deploy:
      replicas: 2
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660

  region_identifier:
    build: ../region_identifier/app
    restart: always
    expose:
      - 660
    environment:
      - TEST_END_POINT=/geocoding/identify_region
      - END_POINT=/geocoding/areaLocator
      - GEOCODE_IP=http://proxy:80/geocoding/geocode
    volumes:
      - ../region_identifier/app:/app
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660

  # Audio
  audio_diarization:
    build: ../audio_diarization/app
    restart: always
    expose:
      - 660
    environment:
      - DIARIZATION_END_POINT=/speech/diarize
    volumes:
      - ../audio_diarization/app:/app
    deploy:
      replicas: 2
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660

  speech_to_text:
    build: ../speech_to_text/app
    restart: always
    expose:
      - 660
    environment:
      - STT_END_POINT=/speech/stt
      - GENDER_URL=http://proxy:80/speech/gender
    volumes:
      - ../speech_to_text/app:/app
    deploy:
      replicas: 2
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660

  audio-gender-recognition:
    build: ../audio-gender-recognition/app
    restart: always
    expose:
      - 660
    deploy:
      replicas: 2
    environment:
      - GENDER_END_POINT=/speech/gender
    volumes:
      - ../audio-gender-recognition/app:/app
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660

  # crud_data
  crud_data:
    build: ../labeling-database/crud_data
    restart: always
    expose:
      - 660
    deploy:
      replicas: 2
    environment:
      - STT_PUT_DATA_ENDPOINT=/ai/labeling/stt_put_data
      - STT_UPDATE_ENDPOINT=/ai/labeling/stt_update_data
      - LOCK_ENDPOINT=/ai/labeling/lock_sample
      - GET_UPDATE_SIGNAL_ENDPOINT=/ai/labeling/get_update_signal
      - FETCH_DATA_ENDPOINT=/ai/labeling/fetch_data
      - DOCS_ENDPOINT=/ai/labeling/crud_docs
      - OPENAPI_URL_ENDPOINT=/ai/labeling/crud_openapi.json
    volumes:
      - ../labeling-database/crud_data:/app
      - /etc/localtime:/etc/localtime:ro # for clock
    command: uvicorn entry_point:app --host 0.0.0.0 --port 660
    depends_on:
      - kafka
      - minio
      - postgres

  speech_to_text_stream:
    build: ../speech_to_text_stream/app
    restart: always
    deploy:
      replicas: 2
    environment:
      - IN_STT_TOPIC=STT_IN_TOPIC
      - OUT_STT_TOPIC=STT_OUT_TOPIC
    volumes:
      - ../speech_to_text_stream/app:/app
    command: python entry_point.py
    depends_on:
      - kafka

  audio_gender_recognition_stream:
    build: ../audio_gender_recognition_stream/app
    restart: always
    deploy:
      replicas: 2
    environment:
      - AUDIO_GENDER_IN_TOPIC=AUDIO_GENDER_IN_TOPIC
      - AUDIO_GENDER_OUT_TOPIC=AUDIO_GENDER_OUT_TOPIC
    volumes:
      - ../audio_gender_recognition_stream/app:/app
    command: python entry_point.py
    depends_on:
      - kafka

  update_db_gender:
    build: ../labeling-database/update_db_gender
    restart: always
    deploy:
      replicas: 1
    environment:
      - AUDIO_GENDER_OUT_TOPIC=AUDIO_GENDER_OUT_TOPIC
    volumes:
      - ../labeling-database/update_db_gender:/app
    command: python entry_point.py
    depends_on:
      - kafka
      - postgres

  update_db_stt:
    build: ../labeling-database/update_db_stt
    restart: always
    deploy:
      replicas: 1
    environment:
      - STT_OUT_TOPIC=STT_OUT_TOPIC
    volumes:
      - ../labeling-database/update_db_stt:/app
    command: python entry_point.py
    depends_on:
      - kafka
      - postgres

  # Databases
  elasticsearch:
    image: elasticsearch:8.4.2
    container_name: elasticsearch
    restart: always
    hostname: elasticsearch
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - vm_max_map_count=262144
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - elasticsearch-data-volume:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"

  kibana:
    container_name: kibana
    restart: always
    image: kibana:8.4.2
    hostname: kibana
    environment:
      SERVER_NAME: kibana
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  minio:
    image: minio/minio:latest
    restart: always
    container_name: minio
    hostname: minio
    expose:
      - "9000"
      - "9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minio12345}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minio12345}
    command: server --console-address ":9001" /data
    volumes:
      - ./minio_data:/data

#  minio_client:
#    image: minio/mc:latest
#    hostname: minio_client
#    container_name: minio_client
#    depends_on:
#      - minio
#    entrypoint:


  postgres:
    image: postgres:14.5
    hostname: db
    restart: always
    environment:
      - POSTGRES_HOST_AUTH_METHOD=trust
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  pgadmin:
    container_name: pgadmin_ai_dataset
    image: dpage/pgadmin4:6.13
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-admin@admin.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-secrete}
      PGADMIN_LISTEN_PORT: 80
      MAX_LOGIN_ATTEMPTS: 100
    ports:
      - "9011:80"
    volumes:
      - ./pgadmin_data:/var/lib/pgadmin

  # stream
  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: always
    ports:
      - "9010:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - kafka

  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.12
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:5.5.12
    hostname: kafka
    ports:
      - "9092:9092"
      - '29092:29092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:29092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-192.168.1.119}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"



#      KAFKA_BROKER_ID: 1
#      KAFKA_ADVERTISED_HOST_NAME: kafka
#      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
#      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
#      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
#      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
#      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
#      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: "zookeeper:2181"
#
#      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
#      CONFLUENT_METRICS_ENABLE: 'true'
#      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'


volumes:
  elasticsearch-data-volume:
    driver: local
#
#  minio-data-volume:
#    driver: local
#
#  postgres-data-volume:
#    driver: local
#
#  pgadmin-data-volume:
#    driver: local